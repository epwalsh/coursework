\documentclass[12pt]{article}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{parskip}
\usepackage{amsthm}
\usepackage{thmtools}
\usepackage[headheight=15pt]{geometry}
\geometry{a4paper, left=20mm, right=20mm, top=30mm, bottom=30mm}
\usepackage{graphicx}
\usepackage{bm} % for bold font in math mode - command is \bm{text}
\usepackage{enumitem}
\usepackage{fancyhdr}
\usepackage{amssymb} % for stacked arrows and other shit
\pagestyle{fancy}
\usepackage{changepage}
\usepackage{mathcomp}
\usepackage{tcolorbox}

\declaretheoremstyle[headfont=\normalfont]{normal}
\declaretheorem[style=normal]{Theorem}
\declaretheorem[style=normal]{Proposition}
\declaretheorem[style=normal]{Lemma}
\newcounter{ProofCounter}
\newcounter{ClaimCounter}[ProofCounter]
\newcounter{SubClaimCounter}[ClaimCounter]
\newenvironment{Proof}{\stepcounter{ProofCounter}\textsc{Proof.}}{\hfill$\square$}
\newenvironment{claim}[1]{\vspace{1mm}\stepcounter{ClaimCounter}\par\noindent\underline{\bf Claim \theClaimCounter:}\space#1}{}
\newenvironment{claimproof}[1]{\par\noindent\underline{Proof of claim \theClaimCounter:}\space#1}{\hfill $\blacksquare$ Claim \theClaimCounter}
\newenvironment{subclaim}[1]{\stepcounter{SubClaimCounter}\par\noindent\emph{Subclaim \theClaimCounter.\theSubClaimCounter:}\space#1}{}
% \newenvironment{subclaimproof}[1]{\begin{adjustwidth}{2em}{0pt}\par\noindent\emph{Proof of subclaim \theClaimCounter.\theSubClaimCounter:}\space#1}{\hfill
% $\blacksquare$ \emph{Subclaim \theClaimCounter.\theSubClaimCounter}\vspace{5mm}\end{adjustwidth}}
\newenvironment{subclaimproof}[1]{\par\noindent\emph{Proof of subclaim \theClaimCounter.\theSubClaimCounter:}\space#1}{\hfill
$\Diamond$ \emph{Subclaim \theClaimCounter.\theSubClaimCounter}}
\allowdisplaybreaks

\title{STAT 642: HW 5}
\author{Evan P. Walsh}
\makeatletter
\let\runauthor\@author
\let\runtitle\@title
\makeatother
\lhead{\runauthor}
\chead{\runtitle}
\rhead{\thepage}
\cfoot{}

\begin{document}
\maketitle

\subsection*{1}
\begin{tcolorbox}
Let $\left\{ X_{n} \right\}_{n\geq 1}$ be iid random variables. Let $S_{n} := \sum_{j=1}^{n}X_{j}$ and $0 < p < \infty$.
\begin{enumerate}[label=(\alph*),topsep=3mm]
\item If $E|X_{1}|^{p} = \infty$, then show that 
\[ \limsup_{n\rightarrow\infty}\frac{|S_{n}|}{n^{1/p}} = \limsup_{n\rightarrow\infty}\frac{|X_{n}|}{n^{1/p}} = \infty \ \text{almost certainly}. \]
\item If $0 < p < 2$ and if $E|X_{1}|^{p} < \infty$, where $EX_{1} = 0$ when $1 \leq p < 2$, then show that 
\[ \lim_{n\rightarrow\infty}\frac{S_{n}}{n^{1/p}} = \lim_{n\rightarrow\infty}\frac{X_{n}}{n^{1/p}} = 0 \ \text{almost certainly}. \]
\end{enumerate}
\end{tcolorbox}
\begin{enumerate}[label=(\alph*),topsep=3mm]
\item \begin{Proof}
First we will show that $X := \limsup_{n\rightarrow\infty}\frac{|X_{n}|}{n^{1/p}} = \infty$ a.s. Now, since $X$ is a tail random variable based on a
sequence of independent random variables, $X$ is degenerate. Thus, there exists some $c \in [0,\infty]$ such that $P(X = c) = 1$. By way of
contradiction suppose that $c < \infty$. So $P\left( \limsup_{n\rightarrow\infty}\frac{|X_{n}|}{n^{1/p}} = c \right) = 1$, which implies 
\[ P\left( \frac{|X_{n}|}{n^{1/p}} > (c+1)\ \text{i.o.} \right) = 0. \]
So by the Borel 0-1 Law, $\sum_{n=1}^{\infty}P\left( \frac{|X_{n}|}{n^{1/p}} > c + 1 \right) < \infty$. But then 
\[ E|X_{1}|^{p} \leq 1 + \sum_{n=1}^{\infty}P\left( |X_{1}| > (c+1)n^{1/p} \right) = 1 + \sum_{n=1}^{\infty}P\left( |X_{n}| > (c+1)n^{1/p} \right) <
\infty. \]
This is a contradiction, so $P(X = \infty) = 1$. Now consider $S := \limsup_{n\rightarrow\infty}\frac{|S_{n}|}{n^{1/p}}$. Like $X$, $S$ is a tail
random variable based on an independent sequence of random variables, so $S$ is degenerate. Therefore there exists some $d \in [0,\infty]$ such that
$P(S = d) = 1$. By way of contradiction, suppose $d < \infty$. Then,
\[ \limsup_{n\rightarrow\infty}\frac{|X_{n}|}{n^{1/p}} \leq \limsup_{n\rightarrow\infty}\frac{|S_{n}|}{n^{1/p}} +
\limsup_{n\rightarrow\infty}\frac{|S_{n-1}|}{(n-1)^{1/p}}\left(\frac{n-1}{n}\right)^{1/p} \leq 2d\ \text{a.s.} \]
Now proceed as above with $X$ and some $c \leq 2d < \infty$.
\end{Proof}

\item \begin{Proof}
First suppose $0 < p < 1$. Then by Theorem 4.15, for any $c \in \mathbb{R}$,
\[ 0 = \lim_{n\rightarrow\infty}\frac{S_{n} - nc}{n^{1/p}} =\lim_{n\rightarrow\infty} \left(\frac{S_{n}}{n^{1/p}} - \frac{nc}{n^{1/p}}\right) 
= \lim_{n\rightarrow\infty}\frac{S_{n}}{n^{1/p}} - \lim_{n\rightarrow\infty}n^{1 - 1/p}c = \lim_{n\rightarrow\infty}\frac{S_{n}}{n^{1/p}} \
\text{a.s.} \]
So $\lim_{n\rightarrow\infty}|S_{n}| / n^{1/p} = 0$ a.s. Further,
\[ \lim_{n\rightarrow\infty}\frac{X_{n}}{n^{1/p}} = \frac{S_{n}}{n^{1/p}} - \frac{S_{n-1}}{(n-1)^{1/p}}\left( \frac{n-1}{n} \right)^{1/p} = 0\ \text{
a.s.} \]
Now suppose $1 \leq p < 2$ and $EX_{1} = 0$. Then by Theorem 4.15 again,
\[ \lim_{n\rightarrow\infty}\frac{S_{n}}{n^{1/p}} = 0 \ \text{a.s.} \]
It follows that $\lim_{n\rightarrow\infty}X_{n}/n^{1/p} = 0$ a.s. as well, just as in the first case.
\end{Proof}
\end{enumerate}


\newpage 
\subsection*{2 [AL 8.12]}
\begin{tcolorbox}
Show that equation (4.12) in chapter 8 of AL holds with $p \in (0,2) \setminus \{1\}$.
\end{tcolorbox}
\begin{Proof}
\begin{description}[leftmargin=4mm]
\item[Case 1:] $p \in (1,2)$.

By assumption, $EX_{1} = 0$. Therefore $0 = E[X_{1}I(|X_{1}|^{p} \leq n)] + E[X_{1}I(|X_{1}|^{p} > n)]$ for all $n \geq 1$. Therefore 
\[ |EZ_{n}| = \big|E[X_{n}I(|X_{n}|^{p} \leq n)]\big| = \big|E[X_{1}I(|X_{1}|^{p} \leq n)]\big| = \big|E[X_{1}I(|X_{1}|^{p} > n)]\big|, \ \forall \ n \geq 1. \]
Thus,
\begin{align*}
\sum_{n=1}^{\infty}|E[Z_{n}]|n^{-1/p} & \leq \sum_{n=1}^{\infty}E\left[ |X_{1}|I(|X_{1}|^{p} > n) \right]n^{-1/p} \\
& = \sum_{n=1}^{\infty}\sum_{j=n}^{\infty} E\left[ |X_{1}|I(j < |X_{1}|^{p} \leq j+1) \right]n^{-1/p} \\
& = \sum_{j=1}^{\infty}\sum_{n=1}^{j}E\left[ |X_{1}|I(j < |X_{1}|^{p} \leq j + 1) \right]n^{-1/p} \\
\text{by AL (4.10) } & = \sum_{j=1}^{\infty}E\left[ |X_{1}|I(j < |X_{1}|^{p} \leq j + 1) \right]\left( \frac{j^{1-1/p}}{1-1/p} \right) \\
& = \sum_{j=1}^{\infty}E\left[ |X_{1}|^{2-1/p}|X_{1}|^{1/p-1}I(j < |X_{1}|^{p} \leq j + 1) \right]\left( \frac{j^{1-1/p}}{1-1/p} \right) \\
& = \sum_{j=1}^{\infty}E\left[ |X_{1}|^{p}|X_{1}|^{1/p-1}I(j < |X_{1}|^{p} \leq j + 1) \right]\left( \frac{j^{1-1/p}}{1-1/p} \right) \\
& \leq \sum_{j=1}^{\infty}E\left[ |X_{1}|^{p}I(j < |X_{1}|^{p} \leq j + 1) \right](j+1)^{1/p - 1}(j+1)^{1-1/p}\left( \frac{p}{p-1} \right) \\
& \leq \frac{p}{p-1}E|X_{1}|^{p} < \infty.
\end{align*}
Therefore by Kronecker's Lemma $n^{-1/p}\sum_{j=1}^{n}EZ_{n} \rightarrow 0$ as $n \rightarrow \infty$.

\item[Case 2:] $p \in (0,1)$.

Similary, we have 
\begin{align*}
\sum_{n=1}^{\infty}|EZ_{n}|n^{-1/p} & \leq \sum_{n=1}^{\infty}E\left[ |Z_{n}| \right]n^{-1/p} \\
& = \sum_{n=1}^{\infty}\sum_{j=1}^{\infty}E\left[ |X_{1}|I(j-1 < |X_{1}|^{p} \leq j) \right]n^{-1/p} \\
& = \sum_{j=1}^{\infty}\sum_{n=j}^{\infty}E\left[ |X_{1}|I(j-1 < |X_{1}|^{p} \leq j) \right]n^{-1/p} \\
\text{by AL (4.9) } & \leq \sum_{j=1}^{\infty}E\left\{ |X_{1}|I(j-1 < |X_{1}|^{p} \leq j) \right\}\left( \frac{1}{1-p} \right)j^{-(1/p-1)} \\
& = \frac{1}{1-p}\sum_{j=1}^{\infty}E\left[ |X_{1}|^{p}|X_{1}|^{1-p}I(j-1 < |X_{1}|^{p} \leq j) \right]j^{-(1/p-1)} \\
& \leq \frac{1}{1-p}\sum_{j=1}^{\infty}E\left[ |X_{1}|^{p}|X_{1}|^{1/p-1}I(j-1 < |X_{1}|^{p} \leq j) \right]j^{-(1/p-1)} \\
& \leq \frac{1}{1-p}\sum_{j=1}^{\infty}E\left[ |X_{1}|^{p}I(j-1 < |X_{1}|^{p} \leq j) \right]j^{1/p-1}j^{1-1/p} \\
& = \frac{1}{1-p}E|X_{1}|^{p} < \infty.
\end{align*}
Now we can apply Kronecker's Lemma just as in Case 1.
\end{description}
\end{Proof}


\newpage
\subsection*{3 [AL 8.29]}
\begin{tcolorbox}
Let $\left\{ X_{n} \right\}_{n\geq 1}$ be a sequence of iid random variables with $F(x) := P(X_{1} \leq x)$ for all $x \in \mathbb{R}$. Fix $0 < p <
1$. Suppose that $F(\zeta_{p} + \delta) > p$ for all $\delta> 0$, where 
\[ \zeta_p := F^{-1}(p) := \inf\left\{ x : F(x) \geq p \right\}. \]
Show that $\hat{\zeta}_{n} := F_{n}^{-1}(p) := \inf\left\{ x : F_{n}(x) \geq p \right\}$ converges to $\zeta_{p}$ w.p. 1, where $F_{n}(x) :=
n^{-1}\sum_{i=1}^{n}I(X_{i} \leq x)$, $x \in \mathbb{R}$, is the empirical distribution function of $X_{1}, \hdots, X_{n}$.
\end{tcolorbox}
\begin{Proof}
Let $0 < p < 1$. Note that $F_{n}(x) \equiv F_{n,\omega}(x)$ is a function of both $x \in \mathbb{R}$ and $\omega \in \Omega$. Now, for each $x \in
\mathbb{R}$,
\begin{equation}
F_{n}(x) - F(x) = \frac{\sum_{i=1}^{n}I(X_{i} \leq x) - nF(x)}{n} = \frac{\sum_{i=1}^{n}Z_{i} - nEZ_{i}}{n} \rightarrow 0 \ \ \text{w.p. 1} 
\label{3.1}
\end{equation}
by Kolmogorov's SLLN, where $Z_{i} := I(X_{i} \leq x)$. For each $k \in \mathbb{N}$, let 
\begin{align*}
E_{0,k} & := \left\{ \omega \in \Omega : F_{n,\omega}(\zeta_{p} + 2^{-k}) \rightarrow F(\zeta_{p} + 2^{-k}) \right\} \text{ and } \\
E_{1,k} & := \left\{ \omega \in \Omega : F_{n,\omega}(\zeta_{p} - 2^{-k}) \rightarrow F(\zeta_{p}-2^{-k})\right\}.
\end{align*}
By \eqref{3.1}, $P(E_{0,k}) = P(E_{1,k}) = 1$ for all $k \in \mathbb{N}$. Therefore $P(E) = 1$ where $E := \cap_{i=0}^{1}\cap_{k=0}^{\infty}E_{i,k}$.
Now let $\omega \in E$ and $\epsilon > 0$. We need to show that there exists some $N \geq 1$ such that 
\[ |F_{n,\omega}^{-1}(p) - \zeta_p| < \epsilon \text{ for all $n \geq N$,} \]
where $F_{n,\omega}^{-1}(p) \equiv F_{n}^{-1}(p) := \inf\left\{ x : F_{n,\omega}(x) \geq p \right\}$.
Choose $K \in \mathbb{N}$ such that $2^{-K} < \epsilon$. Since $\omega \in E_{0,K}\cap E_{1,K}$ and $F(\zeta_{p} + \delta) > p$ for all $\delta
> 0$, there exists some $N_{0}, N_{1} \geq 1$ such that 
$F_{n,\omega}(\zeta_{p} + 2^{-K}) > p$ and $F_{m,\omega}(\zeta_p - 2^{-K}) < p$ whenever $n \geq N_{0}$ and $m \geq N_{1}$. Let $N := \max\left\{
N_{0}, N_{1} \right\}$.
Then 
\[ \zeta_p + 2^{-K} \geq F_{n,\omega}^{-1}(p)\  \ \text{ and }\ \ \zeta_p - 2^{-K} \leq F_{n,\omega}^{-1}(p) \] 
for all $n \geq N$. Hence $|F_{n,\omega}^{-1}(p) - \zeta_p| \leq 2^{-K} < \epsilon$ for all $n \geq N$.
\end{Proof}


\newpage
\subsection*{4 [AL 8.31]}
\begin{tcolorbox}
Let $\left\{ X_{n} \right\}_{n\geq 1}$ be iid random variables with cdf $F(\cdot)$. For each $\omega \in \Omega$ and $x \in \mathbb{R}$, let
\[ F_{n}(x) := F_{n,\omega}(x) := F_{n}(x,\omega) := n^{-1}\sum_{i=1}^{n}I(X_{i}(\omega)\leq x) \]
be the empirical cdf. Suppose $x_{n} \rightarrow x_{0}$ and $F(\cdot)$ is continuous at $x_{0}$. Show that $F_{n}(x_{n}) \rightarrow
F_{n}(x_{0})$ w.p. 1.
\end{tcolorbox}
\begin{Proof}
Let $E := \left\{ \omega \in \Omega : \sup_{x}|F_{n,\omega}(x) - F(x)| \rightarrow 0\right\}$. By Theorem AL 8.2.4 (Glivenko-Cantelli) $P(E) = 1$.
Now let $\epsilon > 0$ and $\omega \in E$. Since $F$ is continuous at $x_{0}$, there exists some $N_{0} \geq 1$ such that $|F(x_{n}) - F(x_{0})| <
\epsilon / 2$ whenever $n \geq N$. Further, since $\omega \in E$, there exists some $N_{1}$ such that $\sup_{x}|F_{n}(x) - F(x)| < \epsilon / 2$.
Let $N := \max\left\{ N_{0}, N_{1} \right\}$. Then for all $n \geq N$,
\[ |F_{n}(x_{n}) - F(x_{0})| \leq |F_{n}(x_{n}) - F(x_{n})| + |F(x_{n}) - F(x_{0})| < \epsilon / 2 + \epsilon / 2 = \epsilon. \]
\end{Proof}



\end{document}

